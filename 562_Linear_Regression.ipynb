{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-NC6NrCwO6H",
        "outputId": "99a1e015-c413-4698-902d-db5f5910fc1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.6644118401490493, 31.69449950876324, 5.629786808464708, 0.6967641778391525)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/sri_lanka_precipitation_cleaned.csv')\n",
        "\n",
        "# Selecting relevant features\n",
        "features = ['city', 'temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean',\n",
        "            'apparent_temperature_max', 'apparent_temperature_min', 'apparent_temperature_mean',\n",
        "            'shortwave_radiation_sum', 'windspeed_10m_max', 'windgusts_10m_max',\n",
        "            'winddirection_10m_dominant', 'et0_fao_evapotranspiration', 'latitude', 'longitude', 'elevation',\n",
        "            'precipitation_hours', 'weathercode', 'year', 'month']\n",
        "target = 'precipitation_sum'\n",
        "\n",
        "# Splitting the dataset into features and target\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Define a column transformer for One-Hot Encoding\n",
        "column_transformer = ColumnTransformer([\n",
        "    ('city_encoder', OneHotEncoder(), ['city']),\n",
        "    ('weathercode_encoder', OneHotEncoder(), ['weathercode'])\n",
        "], remainder='passthrough')\n",
        "\n",
        "# Apply the transformations\n",
        "X_transformed = column_transformer.fit_transform(X)\n",
        "\n",
        "# Scaling the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_transformed)\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training the Linear Regression model\n",
        "linear_regression = LinearRegression()\n",
        "linear_regression.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions and evaluating the model\n",
        "predictions = linear_regression.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "(mae, mse, rmse, r2)\n"
      ]
    }
  ]
}